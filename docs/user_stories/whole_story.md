## エージェント利用のユーザーストーリー

添付画像の「エージェント管理システム」のページを想定し、エージェント利用におけるユーザーストーリーを以下に記述します。

---

### ストーリー1：アイデアから目的・コンテキストの構造化（抽象エージェント）

**目的:** ユーザーは、漠然とした事業アイデアや業務改善の課題に対し、対話を通じてその目的とコンテキストを明確に構造化し、次の具体的なステップを明らかにしたい。

**アクター:** 新規事業企画担当者、業務改善リーダー、プロダクトマネージャー

**シナリオ:**

1.  **アイデアの着想:** ユーザーは、例えば「既存顧客の解約率を低減させたいが、具体的なアプローチが見つからない」といった漠然とした課題を抱えている。
2.  **抽象エージェントの起動:** ユーザーは「エージェント管理システム」にアクセスし、汎用的な「アイデア構造化エージェント」や「課題解決アシスタント」のような、抽象度の高いエージェントを選択して起動する。これは、具体的なタスクに特化する前のブレインストーミングパートナーとして機能する。
3.  **対話による深掘り:**
    * エージェントは、「解約率低減の目的は何ですか？」「現在の顧客のライフサイクルで、特にどのフェーズに問題があると感じていますか？」といった多角的な質問をユーザーに投げかける。
    * ユーザーは、エージェントの質問に対し、自身の思考や情報を自然言語で応答する。思考が整理されていない部分もそのまま入力する。
    * エージェントは、ユーザーの応答をリアルタイムで解析し、関連キーワードの抽出、論点のマッピング、潜在的な問題点の示唆などを行いながら、次の質問や提案を生成する。この過程で、ユーザーは自身の漠然としたアイデアが整理され、具体的な要素に分解されていくのを感じる。
4.  **目的とコンテキストの明確化:** 数回の対話を通じて、ユーザーは「既存顧客の中でも、特にサービス導入後3ヶ月以内の利用頻度低下が主な原因であり、その層への個別最適化されたオンボーディングサポートが有効である」といった、具体的な目的と必要なコンテキストを明確に構造化できる。
5.  **次のステップの提示:** エージェントは、明確化された目的とコンテキストに基づき、「関連データの分析エージェント」「オンボーディング改善施策立案エージェント」といった、具体的な次のアクションに繋がる専門エージェントの利用を提案する。

---

### ストーリー2：明確化された目的に基づくタスク実行（直接実行）

**目的:** ユーザーは、明確になった目的とコンテキストに基づき、エージェントに直接、特定のタスクを実行させ、その結果を迅速に得たい。

**アクター:** 一般ユーザー、学生、主婦・主夫、会社員

**シナリオ:**

1.  **目的の特定:** ユーザーは、すでに「Pythonでウェブアプリを開発するためのフレームワーク（Django、Flask、FastAPI）の特徴、メリット・デメリット、学習コストを比較して、自分のプロジェクトに最適なものを選択したい」という明確な目的と、比較したい項目を持っている。
2.  **専門エージェントの選択:** ユーザーは「エージェント管理システム」から、目的に合致する「技術比較エージェント」や「情報収集エージェント」を選択し、起動する。
3.  **パラメータの入力と実行指示:** ユーザーは、エージェントが求める必須パラメータ（例: 比較対象の技術スタック、評価したい観点、プロジェクトの規模や要件など）をUI上で入力するか、自然言語で指示する。
4.  **エージェントによる自動実行:** エージェントは、入力された情報に基づき、バックグラウンドで複数の技術ドキュメント、開発者ブログ、Stack Overflow、GitHub、技術メディアから情報を収集し、各フレームワークの特徴、パフォーマンス、コミュニティサイズ、学習リソースなどを体系的に整理・比較する。この際、ユーザーは進捗状況をUI上で確認できる。
5.  **結果の受領と活用:** タスクが完了すると、エージェントは調査結果を比較表形式（例: 各フレームワークの特徴一覧、パフォーマンス比較、学習難易度、利用シーン別の推奨度、公式ドキュメントや学習リソースのリンク集など）でユーザーに提示する。ユーザーはこの結果を基に、すぐに自分のプロジェクトに適したフレームワークを決定し、学習や開発に着手できる。エージェントのステータスは「完了」となる。

---

### ストーリー3：複雑な目的のための専門エージェントへの委譲（間接実行）

**目的:** ユーザーは、自身の複雑な目的を達成するために、複数の専門知識や手順を必要とするタスクを、最適な専門エージェントに自動的に委譲し、その進捗を管理したい。

**アクター:** 個人開発者、スタートアップ創業者、システム設計担当者

**シナリオ:**

1.  **複雑な目的の提示:** ユーザーは「ECサイトを構築するための最適な技術スタック全体を選定し、各技術の組み合わせ相性や開発・運用コストも含めて総合的に判断したい」という比較的複雑で多岐にわたる目的を、抽象度の高い「技術スタック選定アシスタント」エージェントに伝える。
2.  **目的の分解と委譲先の推定:** 「技術スタック選定アシスタント」エージェントは、ユーザーの目的を解析し、それを達成するために必要な複数の下位タスク（例: 「フロントエンド技術調査」「バックエンド技術調査」「データベース技術調査」「インフラ・デプロイ技術調査」「決済システム調査」）を識別する。
    * エージェントは、これらの下位タスクそれぞれに対応する、より専門的な「フロントエンド技術比較エージェント」「バックエンド技術比較エージェント」「データベース技術比較エージェント」「クラウドインフラ比較エージェント」「決済システム比較エージェント」といったサブエージェント群をシステム内で推定する。
3.  **委譲の承認と実行:**
    * エージェントは、特定された下位タスクと、それらを処理するのに適したサブエージェントのリストをユーザーに提示し、委譲の承認を求める。
    * ユーザーが承認すると、「技術スタック選定アシスタント」エージェントは、それぞれのサブエージェントに必要なコンテキスト（プロジェクト規模、予想トラフィック、チームスキルレベルなど）と初期データを与え、タスクを自動的に委譲する。
    * 抽象エージェントのステータスは「待ち状態」（または「委譲済み」）に更新される。
4.  **サブエージェントによる並行処理と協調:**
    * 委譲された各サブエージェントは、それぞれの専門領域でタスクを実行する。例えば、「フロントエンド技術比較エージェント」はReact/Vue/Angularの比較調査を行い、「バックエンド技術比較エージェント」はNode.js/Python/Goの特徴分析を行う。
    * 必要に応じて、サブエージェント間で情報の受け渡しや連携が行われる。例えば、フロントエンド技術の選択結果がバックエンド技術の推奨に影響を与える。
5.  **進捗の統合と結果の提示:** 各サブエージェントのタスク完了状況は、「技術スタック選定アシスタント」エージェントに集約され、ユーザーは全体的な進捗状況をUI上で確認できる。全てのサブエージェントのタスクが完了すると、「技術スタック選定アシスタント」エージェントは、各サブエージェントからの結果を統合し、最終的な「ECサイト開発のための推奨技術スタック選定レポート」を生成してユーザーに提示する。このレポートには、各技術の相性マトリクス、総合開発コスト見積もり、チーム習得難易度なども含まれる。

---

### ストーリー4：要件定義からコーディング仕様への落とし込み（対話型開発支援）

**目的:** ユーザーは、アプリケーションや機能の漠然とした要件を、エージェントとの対話を通じて具体的なコーディング仕様まで落とし込み、開発チームへ連携可能な状態にしたい。

**アクター:** システム開発責任者、プロダクトオーナー、非技術系ビジネスサイド担当者

**シナリオ:**

1.  **初期要件の提示:** ユーザーは「エージェント管理システム」にアクセスし、「要件定義アシスタント」エージェントを起動する。ユーザーは、「顧客からの問い合わせを効率化するチャットボットが欲しい」といった抽象的な要件をエージェントに伝える。
2.  **対話による要件の深掘り:**
    * エージェントは、ユーザーに対して、チャットボットの目的、ターゲットユーザー、主要な機能（例: FAQ応答、予約受付、トラブルシューティング）、既存システムとの連携要件、使用する技術スタック（もしあれば）などについて、具体的な質問を投げかける。
    * ユーザーは質問に回答し、エージェントはそれらの情報を基に要件を段階的に詳細化していく。例えば、「FAQ応答では、どの程度の粒度で回答を生成しますか？」「予約受付は既存の予約システムとどのように連携しますか？」など。
    * この対話の過程で、エージェントはユーザーの意図を汲み取り、曖昧な表現を明確化したり、潜在的なニーズや考慮すべき点（例: セキュリティ、スケーラビリティ）を指摘したりする。
3.  **機能要件の整理と詳細化:** 対話が進むにつれて、エージェントはユーザーとの合意形成に基づき、以下のような項目を構造化された形式で提示する（テスト可能な範囲で簡単な例）：

    * **機能要件例:**
        * **問い合わせ受付機能:**
            * ユーザーからのテキスト入力（自由記述）を受け付ける。
            * 入力された問い合わせ内容からキーワードを抽出し、既存のFAQデータベースを検索する。
            * `テストケース1`: 「営業時間」と入力された場合、「弊社の営業時間は平日9時～17時です。」という回答を返す。
            * `テストケース2`: 「パスワード忘れ」と入力された場合、パスワードリセット手順に関するFAQへのリンクを提示する。
        * **予約受付連携機能:**
            * ユーザーが「予約したい」と入力した場合、予約の目的（例: 製品デモ、サポート相談）を尋ねる。
            * 目的が特定された場合、既存の予約システム（例: Calendly API）に連携し、空き時間を提示する。
            * `テストケース3`: 「製品デモの予約」と入力された場合、Calendlyのデモ予約ページURLを提示する。
            * `テストケース4`: 予約システムが応答しない場合、「現在予約システムに接続できません。後ほどお試しください。」というエラーメッセージを返す。

    * **非機能要件例:**
        * 応答速度: ユーザー入力から回答提示まで3秒以内。
        * 可用性: 24時間365日稼働（定期メンテナンス時間を除く）。

4.  **コーディング仕様の提案（簡易版）:** エージェントは、整理された要件に基づき、開発者がすぐに取り掛かれるような、シンプルでテスト可能なコーディング仕様の骨子を提案する。

    * **APIエンドポイント例:**
        * `POST /api/chatbot/message`: ユーザーメッセージを受け取り、チャットボットの応答を返す。
        * リクエストボディ: `{ "userId": "string", "message": "string" }`
        * レスポンスボディ: `{ "response": "string", "actionType": "string" (e.g., "text", "link", "api_call"), "payload": {} (optional) }`

    * **ロジックフロー例:**
        1.  ユーザーメッセージを受信する。
        2.  自然言語処理モジュールでインテント（意図）とエンティティ（実体）を抽出する。
        3.  抽出されたインテントに基づき、対応するハンドラー関数を呼び出す。
        4.  ハンドラー関数は、FAQデータベース検索、外部API呼び出し（例: 予約システム連携）などを行う。
        5.  結果をチャットボット応答フォーマットに整形して返す。

5.  **開発チームへの連携:** ユーザーは、エージェントが生成した詳細な要件定義書とコーディング仕様の骨子をレビューし、必要に応じて修正を加えた後、開発チームにエージェントの出力結果をそのまま、または一部加工して引き渡す。これにより、要件の認識齟齬が減り、開発の効率化が期待できる。
6.  **エージェントのステータス更新:** タスクが完了し、出力が生成されるとエージェントのステータスは「完了」となる。

---

## エージェント利用の成功判定基準（人間によるレビュー想定）

### ストーリー1：アイデアから目的・コンテキストの構造化（抽象エージェント）

**目的:** ユーザーの漠然としたアイデアが、対話を通じて明確な目的と構造化されたコンテキストに整理されたか。

**客観的な成功基準とレビューポイント:**

1.  **目的の明確性:**
    * **基準:** 対話終了後、ユーザーによって記述された「最終的な目的」が、具体的かつ測定可能な形で記述されているか。
    * **レビュー:**
        * 「何のために、何を達成したいのか」が曖ミなく理解できるか？
        * 曖昧な表現（例:「もっと良くしたい」）が具体的な行動（例:「〇〇機能の利用率を〇%向上させる」）に変換されているか？
        * レビュー担当者にとって、対話開始時のユーザーの課題感と、終了時の目的の記述にギャップがないか、あるいは期待以上の具体性があるか？
2.  **コンテキストの構造化と網羅性:**
    * **基準:** 目的達成に必要な「前提条件」「関連情報」「制約」「考慮すべき点」が、体系的に整理され、不足がないか。
    * **レビュー:**
        * 対話ログやエージェントの出力（要約、キーワードリスト、関連する質問応答履歴など）を確認し、目的達成に不可欠な情報が抜け漏れなく収集されているか？
        * 収集された情報が、単なる羅列ではなく、何らかの論理的なカテゴリや関係性で整理されているか（例: ターゲット層、競合、既存資産、技術的制約など）？
        * ユーザーが対話開始時には意識していなかったが、エージェントとの対話によって引き出された重要なコンテキストがあるか？
3.  **次のステップの具体性:**
    * **基準:** エージェントが提示した「次のアクション」が、具体的な専門エージェントの利用や、次に取り組むべきタスクとして明確に示されているか。
    * **レビュー:**
        * 提示された次のアクションが、構造化された目的とコンテキストから論理的に導き出されているか？
        * 提示された専門エージェントやタスクが、実際にシステム内で実行可能、あるいは人間が取り組めるレベルの粒度になっているか？
        * ユーザーが迷うことなく次の行動に移れるようなガイドになっているか？
4.  **ユーザーの理解度と納得感（間接的評価）:**
    * **基準:** ユーザーが自身の目的とコンテキストを深く理解し、エージェントの出力に納得感を持っているか。
    * **レビュー:**
        * 対話終了後のユーザーからのフィードバック（もしあれば）を確認し、内容が「非常に役立った」「課題が整理できた」といった肯定的なものか？
        * ユーザーが自発的に追加情報を提供したり、より深い質問をしたりする姿勢が見られたか？

---

### ストーリー2：明確化された目的に基づくタスク実行（直接実行）

**目的:** エージェントが、明確な目的に基づき、指定されたタスクを正確かつ効率的に実行し、期待される結果を生成したか。

**客観的な成功基準とレビューポイント:**

1.  **タスク実行の正確性:**
    * **基準:** エージェントが生成した結果が、ユーザーの指示した目的とコンテキストに完全に合致しているか。データ処理の場合、数値や内容に誤りがないか。
    * **レビュー:**
        * 生成されたレポート、分析結果、抽出データなどが、指示された範囲（例: 特定の期間、顧客セグメント）内で正しく処理されているか？
        * 計算結果や統計情報に明らかな誤りがないか（例: 合計値が不整合、相関関係が逆転している）？
        * データソースからの情報取得において、欠損や予期せぬエラーがないか？
2.  **結果の有用性と形式:**
    * **基準:** 生成された結果が、ユーザーが次の行動に移すために十分な情報を含み、かつ適切な形式で提供されているか。
    * **レビュー:**
        * レポートの場合、結論や示唆が明確で、グラフや表が見やすく整理されているか？
        * 提案されたコンテンツパターンなどが、実際に利用可能な形式（例: テキスト、画像URL）で提供されているか？
        * ユーザーが追加の加工なしに結果をすぐに活用できる状態か？
3.  **実行の効率性:**
    * **基準:** タスクが人間が手動で行うよりも迅速に完了し、かつシステムリソースが適切に利用されているか。
    * **レビュー:**
        * タスクの処理時間（開始から完了まで）が、事前に設定されたSLA（Service Level Agreement）を満たしているか、あるいは人間が手動で行う場合の予測時間を大幅に下回っているか？
        * システムログを確認し、処理中に不必要なエラーや再試行が発生していないか？（間接的な効率性指標）
4.  **ステータスの適切性:**
    * **基準:** エージェントのステータスが、タスクの完了を正確に反映しているか。
    * **レビュー:**
        * タスクが正常に完了した場合、「完了」ステータスになっているか？
        * エラーが発生した場合、「エラー」または「失敗」などの適切なステータスになっているか？

---

### ストーリー3：複雑な目的のための専門エージェントへの委譲（間接実行）

**目的:** ユーザーの複雑な目的が、複数の専門エージェントへの適切な委譲によって達成され、その進捗が透過的に管理されたか。

**客観的な成功基準とレビューポイント:**

1.  **目的の適切な分解と委譲:**
    * **基準:** 抽象エージェントが、複雑な目的を論理的に分解し、最適な専門エージェントに正確にタスクを委譲できているか。
    * **レビュー:**
        * 分解された下位タスクが、元の複雑な目的を達成するために全て網羅されているか？
        * 各下位タスクが、委譲された専門エージェントの機能と専門性に合致しているか？（例: 市場調査タスクが市場調査エージェントに委譲されているか）
        * 委譲時に、各サブエージェントに必要なコンテキスト情報やパラメータが正しく引き継がれているか？
2.  **進捗の可視性と統合:**
    * **基準:** ユーザーが、複数のサブエージェントの進捗状況を、抽象エージェントを通じて一元的に、かつリアルタイムに近い形で確認できるか。
    * **レビュー:**
        * UI上で、各サブエージェントの個別のステータス（例: 実行中、完了、エラー）と、全体の進捗状況（例: 〇/〇タスク完了）が明確に表示されているか？
        * サブエージェントからの結果が、最終的に抽象エージェントによって統合され、一貫性のある最終レポートや成果物として提示されているか？
3.  **最終成果物の品質:**
    * **基準:** 各サブエージェントの成果物が統合された最終成果物が、ユーザーの当初の複雑な目的を完全に達成し、高い品質を持っているか。
    * **レビュー:**
        * 最終レポートや提案が、網羅性、論理性、実用性の点で優れているか？
        * 各サブエージェント間の連携がスムーズに行われ、不整合や重複がないか？
        * ユーザーが、最終成果物を見て「当初の複雑な課題に対する答えが出た」と感じるか？
4.  **エラーハンドリングとリカバリ:**
    * **基準:** いずれかのサブエージェントで問題が発生した場合、それが適切に検知され、ユーザーに通知されるか、またはリカバリが試みられるか。
    * **レビュー:**
        * サブエージェントのエラーが親エージェントに正しく伝播し、UIに表示されるか？
        * エラー発生時に、ユーザーが次のアクション（例: 再実行、別のサブエージェントの選択）を判断できる情報が提供されるか？

---

### ストーリー4：要件定義からコーディング仕様への落とし込み（対話型開発支援）

**目的:** ユーザーの抽象的な要件が、エージェントとの対話を通じて、具体的でテスト可能な機能要件、非機能要件、およびシンプルなコーディング仕様の骨子まで詳細化され、開発チームへの連携準備ができたか。

**客観的な成功基準とレビューポイント:**

1.  **要件の明確性と網羅性:**
    * **基準:** 対話終了後、生成された要件定義書が、実装に必要な全ての機能的・非機能的要求を明確に記述しているか。曖昧な表現や前提が排除されているか。
    * **レビュー:**
        * 各機能が「誰が、何を、どのように」できるかが具体的に記述されているか？
        * 非機能要件（性能、セキュリティ、可用性など）が考慮され、測定可能な形で記述されているか？
        * 要件に不足や矛盾がないか（レビュアーが開発者になったつもりで読み、疑問点が出ないか）？
        * ユーザーが当初意識していなかったが、エージェントによって引き出された重要な要件（例: エラーハンドリング、国際化対応など）があるか？
2.  **テストケースの具体性と妥当性:**
    * **基準:** 各機能要件に対して、具体的で、かつその機能が正しく動作するかを検証できるテストケースが提示されているか。
    * **レビュー:**
        * 提示されたテストケースが、機能の期待される動作を網羅しているか（例: 正常系、異常系、境界値など）？
        * テストケースが「入力」「期待される出力」といった形式で明確に記述され、再現性があるか？
        * 開発者がこのテストケースを見れば、実装が正しいかを確認できるレベルになっているか？
3.  **コーディング仕様の実現可能性と整合性:**
    * **基準:** 提案されたコーディング仕様の骨子（APIエンドポイント、ロジックフローなど）が、要件定義と整合しており、一般的な開発プラクティスに基づいているか。
    * **レビュー:**
        * 提案されたAPIやデータ構造が、記述された要件をサポートするために十分かつ適切か？
        * ロジックフローが、要件の動作を正しく表現しており、論理的な飛躍がないか？
        * 提示された仕様が、実際に開発者が実装可能なレベルの粒度になっているか？（例: 使用する技術スタックとの親和性）
        * セキュリティやパフォーマンスなどの非機能要件が、提示された仕様で考慮されているか？
4.  **開発チームへの連携準備状況:**
    * **基準:** 生成された出力が、開発チームがすぐに開発に着手できる形式で提供されているか。
    * **レビュー:**
        * 生成されたドキュメントやコードの骨子が、開発ツールやバージョン管理システムにインポートしやすい形式か？
        * 開発チームがレビューや質問を行う際の共通言語として機能するか？
        * この出力だけで開発チームが「次に何をするべきか」を明確に理解できるか？
        * ユーザーが、この成果物を自信を持って開発チームに引き渡せるレベルにあるか？

これらの基準は、エージェントの出力品質とユーザーの満足度を多角的に評価するために活用できます。

--

実装順序
ストーリー２
→ストーリー１
→ストーリー３
→ストーリー４
